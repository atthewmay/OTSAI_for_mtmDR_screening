
from google.api_core.exceptions import ResourceExhausted,DeadlineExceeded
from dotenv import load_dotenv
from openai import APIConnectionError
import google.generativeai as genai
import pickle
import json
import time
import os
import argparse
import openai
import base64
from CONSTANTS import *
import utils
import prompt_texts.prompt_dicts as prompt_dicts

def parse_arguments():
    parser = argparse.ArgumentParser(description="Grade retinal images for diabetic retinopathy using GPT API.")
#     parser.add_argument(
#         "--image_path", type=str, default=None,
#         help="Path to the directory containing the images to be graded."
#     )
    parser.add_argument(
        "--image_directory", type=str, required=True,
        help="Path to the directory containing the images to be graded."
    )

    parser.add_argument(
        "--model", type=str, default="gpt-4o-mini",
        help="model which to run"
    )

    parser.add_argument(
        "--system_message", type=str, required=True,
    )
    parser.add_argument(
        "--pre_messages", type=str, required=False,
    )
    parser.add_argument(
        "--post_messages", type=str, default=None,
    )
    parser.add_argument(
        "--output_file", type=str, default="outputs/grading_results_full.json"
    )

    parser.add_argument(
        "--overwrite", action='store_true'
    )

    # Change to GROK_API_SECRET_KEY if wanting to use grok
    parser.add_argument(
        "--api_key", type=str, default=None
    )

    parser.add_argument(
        "--kwargs", type=str, default=None, help = '{"key1": "value1", "key2": 2, "key3": true}'
    )
    args = parser.parse_args()

    
    if args.kwargs == "default":
        args.kwargs = json.loads(utils.model2default_kwargs[args.model])
    elif args.kwargs is not None:
        args.kwargs = json.loads(args.kwargs)
    else:
        args.kwargs = {}

    return args

def grade_image(image_path,model,system_message,pre_messages,post_messages,**kwargs):
    """model is a stirng like 'gpt-4o-mini'.
    messages is a list of dicts. It'll have the image message and a user message added as well"""
    """pre_messages is the list generated by a function or it is None. Few shot"""
    # Read and encode the image in base64 format
#     with open(image_path, "rb") as image_file:
#         base64_image = base64.b64encode(image_file.read()).decode("utf-8")
    assert type(pre_messages) == list

    resized_image_bytes = utils.downsize_image(image_path)
    base64_image = base64.b64encode(resized_image_bytes).decode("utf-8")

    if "gemini" in model:
        model = genai.GenerativeModel(model_name = args.model,
                                      system_instruction = system_message)
        image = {'mime_type':'image/jpeg', 'data': base64_image}
        chat = model.start_chat(history=pre_messages)

        successful = False
        i=0
        Max_retries=10
        response=None
        while not successful and i<Max_retries:
            try:
                response = chat.send_message(["Image: ",{'mime_type':'image/png', 'data': base64_image}],
                                          generation_config = genai.GenerationConfig(
#                                     response_mime_type="application/json", response_schema=list[Diagnosis],

                                            response_mime_type="application/json", response_schema=list[Diagnosis],
                                              **kwargs),
                                         )
                successful=True
            except ResourceExhausted:
                print(f"resource error on iteration {i}, waiting {sleep_time*(i+1)}")
                time.sleep(sleep_time*(i+1))
                i+=1
        if not successful:
            print("Max retries reached for this, moving on with response=None")


    else: #grok and gpt
        system_message = [{"role": "system", "content": [{"type": "text", "text":system_message}]}]
        pre_messages = pre_messages #already in list format
        post_messages = [{"role": "user", "content": [{"type": "text", "text":post_messages}]}]

        total_messages = system_message + pre_messages + [
                {"role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
#                         "response_format": {"type": "json_object"},
                        }, ],
                }
            ] + post_messages
        response = client.chat.completions.create(
            model=model,
            messages=total_messages,
#             response_format=Diagnosis,
            **kwargs,
        )
    return response


if __name__ == "__main__":

    load_dotenv(dotenv_path="env_vars.env")


    args = parse_arguments()
    if not args.api_key:
        args.api_key = utils.model2api_key[args.model]
        print(f"assigned API key {args.api_key} using model {args.model}")
    API_KEY = os.getenv(args.api_key)


    sleep_time=3

    if "GEMINI" in args.api_key:
#     base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
        genai.configure(api_key=API_KEY)
        sleep_time=3
    else:
        if "GROK" in args.api_key:
            base_url = "https://api.x.ai/v1"
            sleep_time=61 # Gotta get around the requests per hour
        else:
            base_url = None
#     openai.api_base = "https://api.x.ai/v1"
        client = openai.OpenAI(
            api_key=API_KEY,
            base_url=base_url,
        )

# 
# if "gemini" in args.model:
# # Define your output structure as a TypedDict
#     import typing_extensions as typing
#     class Diagnosis(typing.TypedDict):
#         RDR: bool
#         ME: bool
#         Gradable: bool
# else:
#     from pydantic import BaseModel
#     class Diagnosis(BaseModel):
#         RDR: bool
#         ME: bool
#         Gradable: bool
# 

    if "gemini" in args.model:
# Define your output structure as a TypedDict
        import typing_extensions as typing
        class Diagnosis(typing.TypedDict):
            mtmDR: bool
    else:
        from pydantic import BaseModel
        class Diagnosis(BaseModel):
            mtmDR: bool

# Loop through up to 10 images and grade each one independently
    results = []
    running_cost = 0

    system_message = getattr(prompt_dicts,args.system_message)
    if args.pre_messages: 
        pre_messages = getattr(prompt_dicts,args.pre_messages)(args.model) # applies the model name to the correct partial function
    else: #if an empty string
        pre_messages = []

# The folloiwng allows an empty string to show up as empty list instead. Useful for bash loop iterations
# post_messages = getattr(prompt_dicts, args.post_messages if args.post_messages else None, [])
    post_messages = getattr(prompt_dicts, args.post_messages or "", [])


    dict_of_counters = utils.dictOfCounters() # Will be a dict of of sets
    None_logprob_count = 0

    output_file_path = args.output_file

# Handle overwrite or initialize the output file
    processed_images = set()
    if args.overwrite or not os.path.exists(output_file_path):
        # Overwrite or create a new file
        with open(output_file_path, "w") as output_file:
            output_file.write("[")  # Start the JSON array
    else:
        # Load existing entries if file exists and overwrite is False
        processed_images = utils.reopen_file_and_get_processed_images(output_file_path)
#     with open(output_file_path, "r") as existing_file:
#         try:
#             # The following will modify the file
#             existing_data = json.load(existing_file)
#             utils.reopen_file_and_get_processed_images()
#             processed_images = {entry["image_name"] for entry in existing_data}
# 
#         except json.JSONDecodeError:
#             print("Existing file is not valid JSON. Starting fresh.")
#             with open(output_file_path, "w") as output_file:
#                 output_file.write("[")  # Start the JSON array

# Open output file for appending if not overwriting
    output_mode = "a" if not args.overwrite else "w"
    with open(output_file_path, output_mode) as output_file:
        # The following should only be invoked if it started a file but was unable to write anything to it.
        if args.overwrite or os.path.getsize(output_file_path) == 0:  # Write the opening bracket if starting fresh
            output_file.write("[")


    try:
        for idx, image_file in enumerate(sorted(os.listdir(args.image_directory))):  # Adjust for your image file type
            if not image_file.lower().endswith(SUPPORTED_TYPES):
                continue
            image_path = os.path.join(args.image_directory,image_file)

            if image_path in processed_images and not args.overwrite:
                print(f"Skipping already processed image: {image_path}")
                continue
            print(f"processing image at {image_path}")

            connection_i = 0
            max_connection_attempts = 15
            connection_successful = False
            while not connection_successful :
                if connection_i>max_connection_attempts:
                    print("unable to acheive connection. Terminating")
                    utils.clean_json_end(output_file_path)
                    raise Exception
                try:
                    response = grade_image(image_path, args.model,system_message,pre_messages,post_messages,**args.kwargs)
                    connection_successful = True
                except (ResourceExhausted, DeadlineExceeded) as e:
                    print(f"experiencing connection issue {connection_i} times. Retrying in 30 sec")
                    connection_i += 1
                    time.sleep(30)


            if response is None:
                print("None response, continuing")
                continue
            total_cost = utils.calculate_prompt_cost(response,args.model)['total_cost']
            running_cost+=total_cost
            if idx%10==0:
                print(f"running_cost={running_cost}")
            try:
                content = utils.get_response_content(response,args.model)
            except:
                content = None
                print(f"no content for {image_path}")

            try:
                response_text = utils.get_reponse_text(response,args.model)
                parsed_json = json.loads(response_text)
#         parsed_json = utils.postprocessed_parsed_json(parsed_json)
#         print(f"parsed_json is {parsed_json}")
            except:
                import pdb; pdb.set_trace()
                print(f"could not parse for {image_path}")
                print(f"response_text = {response_text}")
                parsed_json = None


            # For now this will not work with gemini
            prob_of_true=None
            if parsed_json:
                response_choices = response.candidates[0] if 'gemini' in args.model else response.choices[0]
                if hasattr(response_choices, 'logprobs'):
                    dict_of_counters.update(response_choices)
                    prob_of_true = utils.extract_true_probability(response) # pred prob of rDR 
                    if prob_of_true is None:
                        import pdb; pdb.set_trace()
                        None_logprob_count+=1
            result_entry = {
                "image_name": image_path,
                "raw_response":response.to_dict(),
#         "raw_content":content,
                "parsed_json": parsed_json,
                "prob_of_true":prob_of_true,
            }
            results.append(result_entry)
            with open(output_file_path, "a") as output_file:
                output_file.write(json.dumps(result_entry, indent=2))
                output_file.write(",\n")  # Add a separator for the next entry

            time.sleep(sleep_time)
    except Exception as e:
        print("Globally unable to accomplish the task. The execption is as follows. Saving json gracefully")
        print(e)
        utils.clean_json_end(output_file_path)
        raise


# except Exception as e:
#     print(e)
#     print("Something went wrong, will continue to clean the json file")
    utils.clean_json_end(output_file_path)
# with open(output_file_path, "a") as output_file:
#     output_file.seek(output_file.tell() - 2, os.SEEK_SET)  # Remove the last comma
#     output_file.write("\n]")

    print("The dictionary for the set of all top-logprob tokens is")
# # print(dict_of_counters)
    pickle.dump(dict_of_counters,open("top_logprob_counters.pickle",'wb'))

# print("\n".join([str(e['parsed_json']) for e in results]))
# print([e['prob_of_true'] for e in results])

# Save results to a JSON file
#  
# with open(args.output_file, "w") as output_file:
#     json.dump(results, output_file, indent=2)

    print(f"For this model there were a total of {None_logprob_count} logprobs that could not be processed")
    print(f"Grading completed. Results saved to {args.output_file}")


# # Function to grade an individual image
# def grade_image(image_path, prompt):
#     with open(image_path, "rb") as img_file:
#         response = requests.post(
#             API_URL,
#             headers=headers,
#             json={
#                 "prompt": prompt,
#                 "images": [{"image": img_file.read()}]
#             }
#         )
#        
#     # Check response status
#     if response.status_code == 200:
#         return response.json()
#     else:
#         print(f"Error {response.status_code} for image {image_path.name}")
#         return None
#
